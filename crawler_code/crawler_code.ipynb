{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update_post_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## captcha_verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "2024-03-23 21:43:30.985728+00:00\n",
      "2024-03-23 21\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time, requests\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 \n",
    "import os\n",
    "from datetime import timezone, datetime, timedelta\n",
    "import traceback\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "def find_captcha_dx() :     \n",
    "    captcha_image_url = driver.find_element(By.ID, \"captcha-verify-image\").get_attribute('src')\n",
    "    response = requests.get(captcha_image_url)\n",
    "\n",
    "    with open(\"captcha_image.jpeg\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # import opencv use Edge Detection\n",
    "    captcha_image_path = \"captcha_image.jpeg\"\n",
    "    captcha_image_resorce = cv2.imread(captcha_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    ret, img_gray = cv2.threshold(captcha_image_resorce, 127, 255, cv2.THRESH_BINARY_INV) # 如果大於 127 就等於 0，反之等於 255。\n",
    "    canny = cv2.Canny(img_gray, 30, 150)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "    token = 0\n",
    "    dx = 229\n",
    "    for i, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if (70 < w < 120) & (70 < h < 120) : \n",
    "            # result = {\"dx\" : x, \"dy\" : y, \"dw\" : w, \"dh\" : h, \"wh\" : [w, h]}\n",
    "            # token.append(result)\n",
    "            dx = x*(340/552)\n",
    "            cv2.rectangle(captcha_image_resorce, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            token = 1\n",
    "            break\n",
    "        else : \n",
    "            continue\n",
    "    if token == 1 : \n",
    "        plt.imshow(captcha_image_resorce)\n",
    "        return dx\n",
    "    \n",
    "    for i, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if (75 < w < 120) & (35 < h < 60) : \n",
    "            # result = {\"dx\" : x, \"dy\" : y, \"dw\" : w, \"dh\" : h, \"wh\" : [w, h]}\n",
    "            # token.append(result)\n",
    "            dx = x*(340/552)\n",
    "            cv2.rectangle(captcha_image_resorce, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            token = 1\n",
    "            break\n",
    "        else : \n",
    "            continue\n",
    "    if token == 1 : \n",
    "        plt.imshow(captcha_image_resorce)\n",
    "        return dx\n",
    "\n",
    "    for i, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if (70 < h < 120) : \n",
    "            # result = {\"dx\" : x, \"dy\" : y, \"dw\" : w, \"dh\" : h, \"wh\" : [w, h]}\n",
    "            # token.append(result)\n",
    "            dx = x*(340/552)\n",
    "            cv2.rectangle(captcha_image_resorce, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            token = 1\n",
    "            break\n",
    "        else : \n",
    "            continue\n",
    "    if token == 1 : \n",
    "        plt.imshow(captcha_image_resorce)\n",
    "        return dx\n",
    "    \n",
    "    return dx\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\") # 排程腳本保存每次輸出的 log 使用之分隔線\n",
    "print((datetime.now(timezone.utc) + timedelta(hours=8)))\n",
    "print((datetime.now(timezone.utc) + timedelta(hours=8)).strftime('%Y-%m-%d %H'))\n",
    "verify_results = 0\n",
    "for times in range(10) : # 輸入 70 次驗證碼，都不過的機率是，(2/3)**70，約 等於 10 的負13次方。大概率有其他的問題要處理。\n",
    "    if verify_results == 1 : \n",
    "        print(\"post_index_updata_succeed\")\n",
    "        # driver.close()\n",
    "        driver.quit()\n",
    "        break\n",
    "    else : \n",
    "        pass\n",
    "\n",
    "    try : \n",
    "        driver = webdriver.Edge()\n",
    "        driver.get(\"https://www.tiktok.com/@geevideo\")\n",
    "\n",
    "        # 輸入驗證碼，平均每 3 次成功一次。\n",
    "        for find_dx_times in range(10) : \n",
    "            # 不讀取圓形驗證碼\n",
    "            time.sleep(5)\n",
    "            for second in range(5) : \n",
    "                try:\n",
    "                    btn = driver.find_element(By.CLASS_NAME, \"sc-cSHVUG\")\n",
    "                    print(\"出現圓形驗證碼\")\n",
    "                    driver.refresh()\n",
    "                    time.sleep(3)\n",
    "                    continue\n",
    "                except  : \n",
    "                    print(\"未出現圓形驗證碼\")\n",
    "                    break\n",
    "\n",
    "            # 尋找驗證碼位置\n",
    "            for second in range(20) : # 給 20 秒的判斷時間，防止網路速度不穩\n",
    "                try:\n",
    "                    btn = driver.find_element(By.CLASS_NAME, \"react-draggable\")\n",
    "                    print(\"找到驗證碼_token\")\n",
    "                    time.sleep(1)\n",
    "                    break\n",
    "                except  : \n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "\n",
    "            print(f\"第 {find_dx_times+1} 輸入\") # 7次以後 move 會自己丟失，推測是套件本身的問題。\n",
    "            dx = find_captcha_dx() # 平均 3 次成功辨識 1 次。\n",
    "            btn =  driver.find_element(By.CLASS_NAME, \"react-draggable\")\n",
    "            move = ActionChains(driver)\n",
    "            move.click_and_hold(btn).perform()\n",
    "            move.move_by_offset(dx//3, 0).perform()\n",
    "            move.move_by_offset(dx//3, 0).perform()\n",
    "            move.move_by_offset(dx//3, 0).perform()\n",
    "            move.move_by_offset(dx%3, 0).perform()\n",
    "            move.move_by_offset(-5, 1).perform()\n",
    "            move.release(btn).perform()\n",
    "\n",
    "            time.sleep(3)\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "\n",
    "            # 下載頁面資訊\n",
    "            html_content = driver.page_source\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "            try : \n",
    "                if soup.find(\"a\", {\"class\" : \"css-1wrhn5c-AMetaCaptionLine eih2qak0\", \"tabindex\" : \"-1\"})[\"href\"]:\n",
    "                    print(\"驗證成功\")\n",
    "                    with open(os.path.join(os.path.join(os.path.dirname(os.getcwd()), \"post_index_html\", \"index_data.html\")), \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(html_content)\n",
    "                    verify_results = verify_results+1\n",
    "                    break\n",
    "                else : \n",
    "                    continue\n",
    "            except : \n",
    "                continue\n",
    "            \n",
    "                \n",
    "    except : \n",
    "        # driver.close()\n",
    "        driver.quit()\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post index html parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sigolon1315\\\\Desktop\\\\titok_crawler\\\\post_index_html_backed\\\\2024-03-11 12_index_data.html'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"parser html\")\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas\n",
    "import shutil\n",
    "\n",
    "with open(os.path.join(os.path.dirname(os.getcwd()), \"post_index_html\", \"index_data.html\"), 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "user_post_item_list = soup.find(\"div\", {\"data-e2e\" : \"user-post-item-list\", \"mode\" : \"compact\", \"class\" : \"css-wjuodt-DivVideoFeedV2\"})\n",
    "\n",
    "index_result_list = []\n",
    "user_post_item_list = user_post_item_list.find_all(\"div\", {\"class\" : \"css-x6y88p-DivItemContainerV2 e19c29qe8\"})\n",
    "for user_post_item in user_post_item_list :\n",
    "\n",
    "    post_title = user_post_item.find(\"a\", {\"class\" : \"css-1wrhn5c-AMetaCaptionLine eih2qak0\", \"tabindex\" : \"-1\"})[\"title\"]\n",
    "    post_href = user_post_item.find(\"a\", {\"class\" : \"css-1wrhn5c-AMetaCaptionLine eih2qak0\", \"tabindex\" : \"-1\"})[\"href\"]\n",
    "\n",
    "    index_result = {\n",
    "        \"post_title\" : post_title,\n",
    "        \"post_href\" : post_href\n",
    "    }\n",
    "\n",
    "    index_result_list.append(index_result)\n",
    "    \n",
    "df_update = pandas.DataFrame(index_result_list)\n",
    "\n",
    "df = pandas.read_csv(os.path.join(os.path.dirname(os.getcwd()), \"data_base\", \"post_index.csv\"))\n",
    "df = pandas.concat([df, df_update], ignore_index=True)\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.to_csv(os.path.join(os.path.dirname(os.getcwd()), \"data_base\", \"post_index.csv\"), index=False)\n",
    "\n",
    "parser_time = (datetime.now(timezone.utc) + timedelta(hours=8)).strftime(\"%Y-%m-%d %H\")\n",
    "shutil.move(os.path.join(os.path.dirname(os.getcwd()), \"post_index_html\", \"index_data.html\"), os.path.join(os.path.dirname(os.getcwd()), \"post_index_html_backed\", f'{parser_time}_index_data.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update_post_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get post html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time, requests\n",
    "import os, pandas\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --------------------------------------------------------------------------------- update_post_informatiom -----------------------------------------------------------------------\n",
    "print(\"get_post_html\")\n",
    "driver = webdriver.Edge()\n",
    "driver.get('about:start')\n",
    "\n",
    "df_update = pandas.read_csv(os.path.join(os.path.join(os.path.dirname(os.getcwd()), \"data_base\", \"post_index.csv\")))\n",
    "post_href_list = df_update[\"post_href\"]\n",
    "\n",
    "for parser_times in range(len(post_href_list)) : \n",
    "\n",
    "    driver.execute_script(f\"window.open('{post_href_list[parser_times]}');\")\n",
    "    # print(post_href_list[parser_times])\n",
    "\n",
    "    # 不讀取圓形驗證碼\n",
    "    time.sleep(5)\n",
    "    for second in range(5) : \n",
    "        try:\n",
    "            btn = driver.find_element(By.CLASS_NAME, \"sc-kAzzGY\")\n",
    "            print(\"出現圓形驗證碼\")\n",
    "            driver.refresh()\n",
    "            time.sleep(3)\n",
    "            continue\n",
    "        except  : \n",
    "            print(\"未出現圓形驗證碼\")\n",
    "            break\n",
    "\n",
    "    # 取得所有分頁的編號\n",
    "    all_handles = driver.window_handles\n",
    "\n",
    "    driver.switch_to.window(all_handles[1])\n",
    "\n",
    "    # 等待數據欄位\n",
    "    time.sleep(5)\n",
    "\n",
    "    html_content = driver.page_source\n",
    "    post_id = post_href_list[parser_times].split(\"/\")[-1]\n",
    "    with open(os.path.join(os.path.join(os.path.dirname(os.getcwd()), \"html_data\", f\"{post_id}.html\")), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    # 切回起點視窗\n",
    "    driver.switch_to.window(all_handles[0])\n",
    "\n",
    "# driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parser post data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"parser_post_html\")\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import timezone, datetime, timedelta\n",
    "import shutil, traceback\n",
    "\n",
    "data_result_list = []\n",
    "html_data_folder = os.path.join(os.path.join(os.path.dirname(os.getcwd()), \"html_data\"))\n",
    "for html_data_folder, dirs, html_datas in os.walk(html_data_folder) : \n",
    "    for html_data in html_datas : \n",
    "\n",
    "        try :  \n",
    "            with open(os.path.join(html_data_folder, html_data), 'r', encoding='utf-8') as file:\n",
    "                html_content = file.read()\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            data_div = soup.find(\"div\", {\"class\" : \"css-1npmxy5-DivActionItemContainer er2ywmz0\"})\n",
    "        except : \n",
    "            data_result = {\n",
    "                \"post_id\" : html_data.replace(\".html\", \"\"),\n",
    "                \"post_title\" : None,\n",
    "                \"parser_time\" : (datetime.now(timezone.utc) + timedelta(hours=8)).strftime(\"%Y-%m-%d %H\"),\n",
    "                \"like-count\" : None,\n",
    "                \"comment_count\" : None,\n",
    "                \"collection\" : None,\n",
    "                \"share_count\" : None\n",
    "            }\n",
    "            data_result_list.append(data_result)\n",
    "            break\n",
    "\n",
    "        post_id = html_data.replace(\".html\", \"\")\n",
    "        \n",
    "        try : \n",
    "            post_title = soup.find(\"meta\", {\"property\" : \"twitter:description\", \"data-rh\" : \"true\"})[\"content\"]\n",
    "        except : \n",
    "            post_title = None\n",
    "\n",
    "        try : \n",
    "            like_count = data_div.find(\"strong\", {\"data-e2e\" : \"like-count\"}).text\n",
    "        except : \n",
    "            like_count = None\n",
    "        \n",
    "        try : \n",
    "            comment_count = data_div.find(\"strong\", {\"data-e2e\" : \"comment-count\"}).text\n",
    "        except : \n",
    "            comment_count = None\n",
    "        \n",
    "        try : \n",
    "            collection = data_div.find(\"strong\", {\"data-e2e\" : \"undefined-count\"}).text\n",
    "        except : \n",
    "            collection = None\n",
    "        \n",
    "        try : \n",
    "            share_count = data_div.find(\"strong\", {\"data-e2e\" : \"share-count\"}).text\n",
    "        except : \n",
    "            share_count = None\n",
    "\n",
    "        data_result = {\n",
    "            \"post_id\" : post_id,\n",
    "            \"post_title\" : post_title,\n",
    "            \"parser_time\" : (datetime.now(timezone.utc) + timedelta(hours=8)).strftime(\"%Y-%m-%d %H\"),\n",
    "            \"like-count\" : like_count,\n",
    "            \"comment_count\" : comment_count,\n",
    "            \"collection\" : collection,\n",
    "            \"share_count\" : share_count\n",
    "        }\n",
    "        data_result_list.append(data_result)\n",
    "        \n",
    "        \n",
    "        # 移動 html_data ，保留原始檔以利後續 debug\n",
    "        parser_time = (datetime.now(timezone.utc) + timedelta(hours=8)).strftime(\"%Y-%m-%d %H\")\n",
    "        shutil.move(os.path.join(html_data_folder, html_data), os.path.join(os.path.join(os.path.dirname(os.getcwd()), \"html_data_backed\", f'{parser_time}_{html_data}')))\n",
    "\n",
    "df_update = pandas.DataFrame(data_result_list)\n",
    "\n",
    "# 資料備份\n",
    "df_update.to_csv(os.path.join(os.path.dirname(os.getcwd()), \"data_backed\" ,f\"{(datetime.now(timezone.utc) + timedelta(hours=8)).strftime('%Y-%m-%d %H')}.csv\"), index=False)\n",
    "\n",
    "# 資料串接\n",
    "df = pandas.read_csv(os.path.join(os.path.dirname(os.getcwd()), \"data_base\", \"data_base.csv\"), index_col=None)\n",
    "df = pandas.concat([df, df_update], ignore_index=True)\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 資料更新完成\n",
    "df.to_csv(os.path.join(os.path.dirname(os.getcwd()), \"data_base\", \"data_base.csv\"), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon_crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
